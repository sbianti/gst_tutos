		GStreamer Playback
		¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
http://docs.gstreamer.com/display/GstSDK/Playback+tutorial+1%3A+Playbin2+usage

I) playback-1_playbin.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
⋅ Utilisation + approfondie de playbin.
⋅ Récupération de la liste des metadata.
C'est un plugin, donc certains objets ne sont pas accessibles depuis core.
Il faudra parfois les redéclarer (ex: GST_PLAY_FLAG_[VIDEO|AUDIO|TEXT]).

A/
data.playbin = gst_element_factory_make("playbin", "el playbin");
	→ Une autre façon de créer un pipeline (gst_parse_launch dans basic-1_hello.c cf. HowTo-basics.txt)

B/
g_object_get(data.playbin, "flags", &flags, NULL);
  flags |= GST_PLAY_FLAG_VIDEO | GST_PLAY_FLAG_AUDIO;
  flags &= ~GST_PLAY_FLAG_TEXT;
g_object_set(data.playbin, "flags", flags, NULL); 
	→ Activation de l'audio et de la vidéo, mais pas des sous-titres.

C/
gst_bus_add_watch(bus, (GstBusFunc)handle_message, &data);
	→ Manière asynchrone de récupérer les messages du bus du pipeline.

d/ spécifique glib
g_io_add_watch(io_stdin, G_IO_IN, (GIOFunc)handle_keyboard, &data);
	→ chopper les évènements de stdin.

e/ gmainloop
Requis par gst_bus_add_watch(…) (et g_io_add_watch)

F/ analyze_streams() appelée par handle_message() lors d'un STATE_CHANGED
⋅ g_object_get(data->playbin, "n-video", &data->n_video, NULL);
	→ On récupère les infos contenue dans le flux analysé par la source de playbin. (get("n-video"…))

⋅ g_signal_emit_by_name(data->playbin, "get-video-tags", i, &taglist);
	→ On émet un signal de type Action (voir glib) qui est donc une sorte de fonction à appeler et qui renvoie le GstTagList associé au flux (les metadata).

⋅ gst_tag_list_get_[string](tags, GST_TAG_[AUDIO_CODEC], &str)
	→ Récupération des métadonnés.

⋅ g_object_get(data->playbin, "current-[video]", &data->current_…, NULL);
	→ trivial

G/ handle_keyboard()
⋅ g_object_set(data->playbin, "current-audio", index, NULL);
	→ voir g_io_channel_read_line() pour la réception d'une ligne de texte.


II) playback-2_sub-management.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
⋅ Similaire à playback-1, mais avec gestion des sous-titres.
⇒ Semble y avoir un bug lorsqu'on charge un sous-titre en plus :
  lorsqu'on change de sous-titre, plus rien n'est affiché.


III) playback-3_short-cutting_pipeline.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯


IV) playback-4_progressive_streaming.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 Comment activer le cache de données téléchargées ?
 Comment en contrôler la quantité ?
 Comment conserver ce qui a été téléchargé ?

Par défaut, le flux téléchargé est conservé en mémoire dans des buffers éliminés dès qu'ils ont étés consommés. Dans ce cas, le seul moyen de faire un retour arrière est de re-télécharger ces données.

Ce n'est pas une technique très efficace pour la lecture des flux qui ne sont pas en direct.

Les media-players présentent généralement une barre affichant l'état des données téléchargées accompagnée de la position courante.

L'élément playbin permet le buffering sur disque à travers le flag booléen “download”.

A/
Idem Basic-12

B/
  …
  flags |= GST_PLAY_FLAG_DOWNLOAD;
  g_object_set (pipeline, "flags", flags, NULL);
	→ On veut stocker le flux. L'enum GstPlayFlags est déclarée dans gst-plugins-base.

C/
  g_object_set(pipeline, "ring-buffer-max-size", (guint64)400000, NULL);
	→ Limitation du tampon cyclique à 400000 octets.

D1/
  g_signal_connect(pipeline, "deep-notify::temp-location", G_CALLBACK(cb), NULL);
	→ Le signal “deep-notify” est émit par tout GstObject quand une propriété d'un élément enfant change. Ici, on veut être averti du changement du nom du fichier où stocker les données téléchargées, ce qui arrive lorsque la Queue crée ce fichier.

D2/
	→ Dans la callback, on n'a qu'à récupérer cette propriété et avec:
  g_object_set(G_OBJECT(prop_object), "temp-remove", FALSE, NULL);
	→ Lorsque le pipeline passe PAUSED à READY, le fichier qui est normalement effacé ne l'est pas.

E/ gboolean refresh_ui(CustomData *data)
  GstQuery *query = gst_query_new_buffering(GST_FORMAT_PERCENT);
	→ création d'une requête de type buffering en %

  int n = gst_query_get_n_buffering_ranges(query);
	→ récupère le nombre de buffers stockés

  for (range = 0; range < n_ranges; range++) {
    gint64 start, stop;
    gst_query_parse_nth_buffering_range(query, range, &start, &stop);
    …
	→ récupère les intervalles (en %) des segments téléchargés du flux.

  if (gst_element_query_position(data->pipeline, FORMAT, &position) &&
      GST_CLOCK_TIME_IS_VALID(position) &&
      gst_element_query_duration(data->pipeline, FORMAT, &duration) &&
      GST_CLOCK_TIME_IS_VALID(duration)) {
      …
	→ On récupère la position et la durée (en seconde), et on valide ces valeurs.


V) playback-5_color-balance.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 De l'équilibrage des couleurs (luminosité, contraste, teinte et saturation).
 Comment trouver les canaux disponibles (l'un des 4 précédents) ?
 Comment les changer ?

Playbin implémente l'interface gstcolorbalance (http://gstreamer.freedesktop.org/data/doc/gstreamer/head/gst-plugins-base-libs/html/gst-plugins-base-libs-gstcolorbalance.html). Si un de ses éléments l'implémente aussi, playbin lui transmet les commandes reçues, sinon il ajoute un élément qui l'implémente.

Le code est simple.

Fonctionnalités ajoutées: on peut donner un incrément différent de 10 points (B -34), et on peut donner la valeur exacte (H 40%).


VI) playback-6_audio-visualization.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 Activer une visualisation si le flux ne contient pas de vidéo.

A/ Activer la visualisation
  g_object_get(pipeline, "flags", &flags, NULL);
  flags |= 0x8;
  g_object_set(pipeline, "flags", flags, NULL);
	→ avec 0x8 = «vis - Render visualisation when no video is present»
	  Par défaut, c'est “goom” qui est sélectionné. Si goom n'est pas présent (plugin good) et qu'on ne fait rien de plus, la visualisation sera désactivée.

 _______________________________________________________________________________
|			Les GstRegistry						|
|			¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯						|
| Ils sont une liste de plugins (GstPlugin) et de fonctions pour les manipuler. |
| Chaque GstPlugin correspond au fichier (lib) contenant ce plugin.  		|
| Si une application veut des infos sur un plugin, ou savoir quel plugin 	|
| fournit telles fonctionnalités, elle doit charger le plugin concerné (ou tous)|
| et chercher dedans les infos demandées → c'est une perte de temps !!		|
| Pour éviter cela, GStreamer crée un fichier qui cache ces infos:		|
| (~/.gstreamer-$GST_API_VERSION/registry-$ARCH.bin).				|
 ¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯

B/ Chercher les éléments disponibles pour la visualisation
 list = gst_registry_feature_filter(get_registry_get(), filter_vis_features, FALSE, NULL);
	→ get_registry_get() ⇒ renvoie le registre des plugins
	→ filter_vis_features ⇒ filtre 
	→ False ⇒ renvoie tous les plugins qui correspondent. (True renverrait seulement le 1er)
	→ NULL ⇒ userdata pour le filtre

C/ Filtrer les fonctionnalités d'un plugin
 gboolean filter_vis_features (GstPluginFeature *feature, gpointer data)
	→ Les plugins sont représentés par des GstPlugin qui contiennent des GstPluginFeature.
	  Certaines de ces GstPluginFeature sont des Factories (GstElementFactory), parmis lesquelles on trouve «Generic», «Video/Overlay/Subtitle», «Sink/Audio», ou encore «Visualization».
	  C'est cette dernière catégorie qui nous intéresse.
	  On peut alors encore filtrer par nom et instancier l'élément.


VII) playback-7_custom-playbin-sinks.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 Comment choisir le sink que playbin va utiliser ?
 Comment construire un pipeline complexe en guise de sink ?

Playbin a deux propriétés audio-sink et video-sink. Elles permettent d'utiliser les éléments désirés.
Mais on peut aussi utiliser un assemblage d'éléments incorporé à un Gstbin.

Le bin se connecte au pipeline via un ghostpad (un pad qui joue le rôle d'une passerelle entre l'extérieur et un vrai pad à l'intérieur du bin).

A/ equalizer-3bands
 C'est un égaliseur sonore. Il y a aussi equalizer-10bands et equalizer-nbands.
 Les différentes valeurs des bandes 0, 1 et 2 représentent les intervalles de fréquence [20Hz-100Hz], [101Hz-1100Hz] et [1101Hz-11kHz].

B/
 Connection du pad static de l'égaliseur (1er élément de la «chaine sink») au ghostpad "sink" du bin.
 gst_element_pad_add(bin, ghost_pad) transfert la propriété du ghostpad au bin → pas besoin de le libérer par la suite, ce qui n'est pas le cas du pad originel.


VIIb) playback-7b_custom-playbin-sinks.c:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
Version 2: on peut régler les propriétés des éléments du plugin gaudieffects.
	ex: ./playback-7b_custom-playbin-sinks «vidéo-path» -e burn -p "silent,bool,true;adjustment,uint,175"


VIII) De l'accélération matérielle:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
Dans l'état actuel des choses, chaque constructeur de carte graphique fournie sa propre API pour accéder au GPU ; aucun standard n'a émergé jusqu'à présent.

En date de juillet 2012 (vieux d'un an), il y a au moins 8 APIs différentes d'accéleration vidéo:

Linux:
¯¯¯¯¯
  VAAPI : Intel (POM! … pom pom pom pom!) spécifiée en 2007 pour Xwindow system, opensource, utilisable donc par d'autres manufactureurs (Imagination Technologies et S3 graphics)
	→ Accessible par GStreamer via les plugins gstreamer-vaapi et fluvadec (Fluendo).

  VDPAU : Nvidia 2008, opensource mais personne d'autre ne l'utilise.
	→ Accessible par GStreamer via vdpau et fluvadec.

  XVBA : AMD, c'est une extension de Xv pour X. Nécessite des pilotes propriétaires.
	→ Accessible par GStreamer via fluvadec.

Win:
¯¯¯
  DXVA  → Accessible par GStreamer via fluvadec.

MacOs:
¯¯¯¯¯
  VDA : accélère seulement le décodage du h264.
	→  fluvadec

Indépendants:
¯¯¯¯¯¯¯¯¯¯¯¯
  OpenMax : Khronos group, opensource
	→ gstreamer-omx

  OVD : AMD pour promouvoir le Universal Video Decode
	→ non disponible pour GStreamer

  DCE : Texas Instrument, opensource, pour Linux et ARM.
	→ gstreamer-ducati

C'est à l'application de sélectionner le bon plugin parmis gstreamer-vaapi ou gstreamer-vdpau (cependant, playbin le fait).
Concernant fluendo, c'est lui-même qui détecte à l'exécution quel élément utiliser.

A/ Fonctionnement de l'accélération matérielle
 Elle se décompose en quelque étapes, les plugins offrant un élément pour chacune d'elles.
 Exemple avec gstreamer-vaapi :
 a) vaapidecode   ⇒ Le décodage vidéo
 b) << rien >>	  ⇒ le traitement (post-processing)
 c) vaapiupload	  ⇒ transfert des images brutes vers le GPU
 d) vaapidownload ⇒ récupération des images vers la mémoire
 e) vaapisink 	  ⇒ La présentation des images décodées

(d) sert donc à récupérer des images de la mémoire du GPU pour les traiter dans la RAM. Il est évidemment plus efficace de les laisser dans le GPU.

B/ Deux types de buffers: les conventionnels et les «hardware buffers»
 Les conventionnels voyagent d'éléments en éléments, mais leur contenu est un hardware buffers ID.
 Pour cela, les buffers conventionnels ont des caps spéciales (ex: video/x-fluendo-va), elles permettent à l'auto-plugger de faire ce qu'il faut si le bon plugin est présent.

C/ Le classement des plugins
 Auto-plugg sélectionne parmis les éléments équivalents (au regard des caps) celui qui a le meilleur classement.
 Pour être sûr d'activer l'accélération, il faut trafiquer le classement :

static void enable_factory(const gchar *name, gboolean enable) {
    GstRegistry *registry = NULL;
    GstElementFactory *factory = NULL;
     
    registry = gst_registry_get_default();
    if (!registry) return;
     
    factory = gst_element_factory_find(name);
    if (!factory) return;
     
    if (enable) {
        gst_plugin_feature_set_rank(GST_PLUGIN_FEATURE(factory),
				    GST_RANK_PRIMARY + 1);
    }
    else {
        gst_plugin_feature_set_rank(GST_PLUGIN_FEATURE(factory),
				    GST_RANK_NONE);
    }
     
    gst_registry_add_feature(registry, GST_PLUGIN_FEATURE(factory));
    return;
}

	→ 4 catégories de classement existent: NONE, MARGINAL, SECONDARY et PRIMARY
	  Donc «GST_RANK_PRIMARY + 1» assure de le mettre en tête du classement.
	  Classer un élément à NONE assure qu'il ne sera jamais sélectionné.

Pour terminer, il faut vérifier les codecs supportés par les différents plugins car tous ne sont pas toujours disponibles.


IX) Audio numérique et absence de conversion:
¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯¯
 Les appareils audio modernes, via des câbles S/PDIF, acceptent des données numériques aussi bien qu'analogiques, dans un format compressé ou brut.
 Dans ce cas, GStreamer n'a pas besoin de décoder et peut se contenter d'envoyer au sink avec un traitement minimum.

A/ Fonctionnement interne:
 Il faut d'abord activer l'audio numérique au niveau de la carte son (opération utilisateur). Alors l'audiosink (pulsesink), le détecte et change son input caps en conséquence. ex: audio/x-raw-int ou audio/x-raw-float, voir audio/mpeg, audio/x-ac3, audio/x-eac3 ou encore audio/x-dts.
 Lorsque playbin construit son pipeline, il connecte directement le demuxer au sink, sans y mettre de décodeur.

 Dans le cas où c'est alsasink qui est utilisé, il y a une opération supplémentaire: la sélection du périphérique audio via une de ses propriétés.

B/ Précautions
 Lorsque l'audio numérique est activée, l'audiosink expose toutes les caps possibles car il n'y a aucun moyen de savoir ce dont est capable le périphérique concerné.
 Il peut donc y avoir quelque problèmes au décodage côté périphérique.
 Le seul moyen de résoudre cela est que l'utilisateur intervienne.

 Certains pilotes permettent de sélectionner les formats supportés par le périph. Dans ce cas, GStreamer n'expose que ces caps là.

Une autre solution peut être de créer un sinkbin perso contenant un capsfilter et un sink audio, le capsfilter sachant quels caps accepter. Cela requiert toujours une intervention de l'utilisateur, mais elle est faite au niveau applicatif.

Rq: autoaudiosink ne supporte que raw/audio comme format numérique.
